{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import numpy as np\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import regionmask\n",
    "from cmip_preprocessing_funcs import *\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "print(\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_full(ds_final):\n",
    "    # Convert the xarray dataset to a pandas DataFrame\n",
    "    df_full = ds_final.to_dataframe()\n",
    "\n",
    "    df_full['lat'] = df_full.index.get_level_values('lat')\n",
    "    df_full['lon'] = df_full.index.get_level_values('lon')\n",
    "    # Extract year and month from the time dimension\n",
    "    df_full['year'] = df_full.index.get_level_values('time').year\n",
    "    df_full['month'] = df_full.index.get_level_values('time').month\n",
    "\n",
    "    # Create cyclical features for months\n",
    "    angle = (df_full['month'] - 1) * (2. * np.pi / 12)\n",
    "    df_full['sin_month'] = np.sin(angle)\n",
    "    df_full['cos_month'] = np.cos(angle)\n",
    "\n",
    "    # Drop the month column\n",
    "    del df_full['month']\n",
    "    \n",
    "    df_full['count_nobs'] = df_full['count_nobs'].fillna(0)\n",
    "\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lasting-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_error(df_measured, instrumental_error_std=3):\n",
    "    # Generate spatiotemporal error with varying standard deviation\n",
    "    spatiotemporal_error = np.random.normal(loc=0, scale=df_measured['spco2_cmems_std']) #\n",
    "\n",
    "    # Generate instrumental error\n",
    "    instrumental_error = np.random.normal(loc=0, scale=instrumental_error_std, size=len(df_measured))\n",
    "    \n",
    "    # Calculate the total error\n",
    "    spco2_cmems_random = df_measured['spco2_cmems'] + instrumental_error + spatiotemporal_error\n",
    "    return spco2_cmems_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bibliographic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(errors_df, df_testing, df_full, n_sims):\n",
    "\n",
    "    # Calculate the mean error\n",
    "    spatial_df = errors_df.groupby(level=['lon', 'lat']).mean().mean(axis=1)\n",
    "\n",
    "    # Add MAE as a new column in spatial_df\n",
    "    spatial_df = spatial_df.to_frame(name='mean_error')  # Convert Series to DataFrame if not already\n",
    "    spatial_df['mae'] = errors_df.abs().groupby(level=['lon', 'lat']).mean().mean(axis=1)\n",
    "    spatial_df['rmse'] = np.sqrt(errors_df.pow(2).groupby(level=['lon', 'lat']).mean().mean(axis=1))\n",
    "    spatial_df['med_abs_error'] = errors_df.abs().groupby(level=['lon', 'lat']).median().mean(axis=1)\n",
    "    \n",
    "    spatial_df.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    resolution = 0.25\n",
    "    # Define the range of latitude and longitude\n",
    "    lat_range = np.arange(spatial_df['lat'].min(), spatial_df['lat'].max() + resolution, resolution)  # Adjust the step as needed\n",
    "    lon_range = np.arange(spatial_df['lon'].min(), spatial_df['lon'].max() + resolution, resolution)  # Adjust the step as needed\n",
    "    \n",
    "    # Create a blank grid (DataFrame)\n",
    "    blank_grid = pd.DataFrame(index=pd.MultiIndex.from_product([lat_range, lon_range], names=['lat', 'lon'])).reset_index()\n",
    "    \n",
    "    # Merge the blank grid with spatial_df\n",
    "    merged_df = blank_grid.merge(spatial_df.reset_index(), on=['lat', 'lon'], how='left')\n",
    "\n",
    "    # Set the index back to ['lat', 'lon'] and convert to xarray\n",
    "    merged_df = merged_df.set_index(['lat', 'lon'])\n",
    "    spatial_xr = merged_df.to_xarray()\n",
    "\n",
    "    # Calculate the average weight for each 'time' group\n",
    "    average_weights = df_testing.groupby('time')['area'].transform('mean')\n",
    "\n",
    "    # Normalize weights so that the average weight in each group is 1\n",
    "    normalized_weights = df_testing['area'] / average_weights\n",
    "    \n",
    "    weighted_errors_df = errors_df.mul(normalized_weights, axis=0)\n",
    "\n",
    "    # Calculate weighted mean error\n",
    "    weighted_mean_error = weighted_errors_df.groupby('time').mean()\n",
    "\n",
    "    # Calculate weighted MAE\n",
    "    weighted_mae = weighted_errors_df.abs().groupby('time').mean()\n",
    "\n",
    "    # Calculate weighted RMSE\n",
    "    weighted_rmse = np.sqrt((weighted_errors_df.pow(2)).groupby('time').mean())\n",
    "    \n",
    "    # Calculate weighted med_abs_error\n",
    "    weighted_med_abs_error = weighted_errors_df.abs().groupby('time').median()\n",
    "    \n",
    "    # Combining the statistics\n",
    "    temporal_df = pd.DataFrame({\n",
    "        'mean_error': weighted_mean_error.mean(axis=1),\n",
    "        'mae': weighted_mae.mean(axis=1),\n",
    "        'rmse': weighted_rmse.mean(axis=1),\n",
    "        'med_abs_error': weighted_med_abs_error.mean(axis=1)\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # Initialize a list to store the results\n",
    "    simulation_results = []\n",
    "\n",
    "    # Loop through each simulation\n",
    "    for sim in range(n_sims):  # Assuming n_sims is the number of simulations\n",
    "        sim_column = f'spco2_error_sim{sim}'\n",
    "\n",
    "        # Ensure the column exists in the DataFrame\n",
    "        if sim_column in weighted_errors_df.columns:\n",
    "            # Calculate the statistics\n",
    "            average_error = weighted_errors_df[sim_column].mean()\n",
    "            mae = weighted_errors_df[sim_column].abs().mean()\n",
    "            rmse = np.sqrt((weighted_errors_df[sim_column].pow(2)).mean())\n",
    "            med_abs_error = weighted_errors_df[sim_column].abs().median()\n",
    "            \n",
    "            # Append the results to the list\n",
    "            simulation_results.append({\n",
    "                'simulation': sim,\n",
    "                'average_error': average_error,\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'med_abs_error': med_abs_error\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the list\n",
    "    simulations_df = pd.DataFrame(simulation_results)\n",
    "\n",
    "    return spatial_xr, temporal_df, simulations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "organizational-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSSE(lme, n_clust, n_sims=10):\n",
    "    print(f\"=============== {lme} SIMULATIONS BEGINNING ==============\")\n",
    "    ncpath = f'../Data/Fall 2023/{lme}_Clusters.nc'\n",
    "    ds_final = xr.open_dataset(ncpath)\n",
    "\n",
    "    socat_path = '../Data/Fall 2023/SOCAT.nc'\n",
    "    ds_socat = xr.open_dataset(socat_path)\n",
    "\n",
    "    ds_final['count_nobs'] = ds_socat['count_nobs']\n",
    "    ds_final['spco2_socat_std'] = ds_socat['fco2_std']\n",
    "    ds_final['area'] = ds_socat['area']\n",
    "\n",
    "\n",
    "\n",
    "    df_full = create_df_full(ds_final)\n",
    "    df_testing = df_full.dropna(subset = ['lme']).copy()\n",
    "\n",
    "    rfr_predictors = ['lon', 'lat', 'year', 'sin_month', 'cos_month', \n",
    "                      'SSS', 'SSH', 'SST', 'IceC', 'CHL', 'WindSpeed', 'Bathy', 'MLD', 'mslp', 'pCO2_atm', 'dist']\n",
    "\n",
    "    if lme in ['Chukchi and North Bering Seas', 'Beaufort Sea']:\n",
    "        rfr_predictors.remove('SSH')\n",
    "        rfr_predictors.remove('CHL')\n",
    "\n",
    "    df_measured = df_testing.query(\"count_nobs > 0\").copy()\n",
    "\n",
    "    errors_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    print(\"MODELLING BEGINNING\")\n",
    "    for simulation_id in range(n_sims):\n",
    "        df_measured['spco2_cmems_random'] = assign_error(df_measured)\n",
    "\n",
    "        for i in range(n_clust):\n",
    "            df_model = df_measured.query(f\"c{i} >= 0.1\")\n",
    "            X_all = df_model[rfr_predictors]\n",
    "            Y_all = df_model['spco2_cmems_random'] \n",
    "\n",
    "            rfr_model = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, max_features=7, \n",
    "                                           oob_score=False, random_state=69420)\n",
    "            rfr_model.fit(X_all, Y_all)\n",
    "            df_testing[f'c{i}_pred'] = rfr_model.predict(df_testing[rfr_predictors])\n",
    "\n",
    "        # Create a list comprehension that multiplies corresponding 'cX' and 'cX_pred' columns\n",
    "        products = [df_testing[f'c{i}'] * df_testing[f'c{i}_pred'] for i in range(n_clust)]\n",
    "        spco2_pred = sum(products)\n",
    "        errors_df[f'spco2_error_sim{simulation_id}'] = df_testing['spco2_cmems'] - spco2_pred\n",
    "        print(f'========= SIMULATION {simulation_id} COMPLETE! ============')\n",
    "  \n",
    "\n",
    "\n",
    "    # Align and divide the errors by the standard deviations to get z-scores\n",
    "    aligned_errors_df, aligned_std_df = errors_df.align(df_full['spco2_cmems_std'], axis=0, join='inner')\n",
    "    z_errors_df = aligned_errors_df.div(aligned_std_df, axis=0)\n",
    "\n",
    "    # Calculate statistics for original errors\n",
    "    spatial_xr, temporal_df, simulations_df = calculate_statistics(errors_df, df_testing, df_full, n_sims)\n",
    "\n",
    "    # Calculate statistics for z-scores errors\n",
    "    spatial_z_xr, temporal_z_df, simulations_z_df = calculate_statistics(z_errors_df, df_testing, df_full, n_sims)\n",
    "\n",
    "    \n",
    "    # For xarray datasets, rename variables and then merge\n",
    "    spatial_z_xr = spatial_z_xr.rename({var: var + '_z' for var in spatial_z_xr})\n",
    "    spatial_xr_combined = xr.merge([spatial_xr, spatial_z_xr])\n",
    "\n",
    "    # For pandas DataFrames, add '_z' suffix to columns and then merge\n",
    "    temporal_z_df.columns = [col + '_z' for col in temporal_z_df.columns]\n",
    "    temporal_df_combined = pd.concat([temporal_df, temporal_z_df], axis=1)\n",
    "    \n",
    "    # Similarly, for the simulations DataFrame\n",
    "    simulations_z_df.columns = [col + '_z' for col in simulations_z_df.columns]\n",
    "    simulations_df_combined = pd.concat([simulations_df, simulations_z_df], axis=1)\n",
    "\n",
    "\n",
    "    print(f\"=============== {lme} SIMULATIONS COMPLETE ==============\")\n",
    "    return spatial_xr_combined, temporal_df_combined, simulations_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "viral-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== U.S. Caribbean SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== U.S. Caribbean SIMULATIONS COMPLETE ==============\n",
      "=============== Pacific Islands SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Pacific Islands SIMULATIONS COMPLETE ==============\n",
      "=============== Gulf of Mexico SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Gulf of Mexico SIMULATIONS COMPLETE ==============\n",
      "=============== California Current SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== California Current SIMULATIONS COMPLETE ==============\n",
      "=============== Chukchi and North Bering Seas SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Chukchi and North Bering Seas SIMULATIONS COMPLETE ==============\n",
      "=============== Northeast U.S. SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Northeast U.S. SIMULATIONS COMPLETE ==============\n",
      "=============== Gulf of Alaska SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Gulf of Alaska SIMULATIONS COMPLETE ==============\n",
      "=============== Aleutian Islands SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Aleutian Islands SIMULATIONS COMPLETE ==============\n",
      "=============== Beaufort Sea SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Beaufort Sea SIMULATIONS COMPLETE ==============\n",
      "=============== East Bering Sea SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== East Bering Sea SIMULATIONS COMPLETE ==============\n",
      "=============== Southeast U.S. SIMULATIONS BEGINNING ==============\n",
      "MODELLING BEGINNING\n",
      "========= SIMULATION 0 COMPLETE! ============\n",
      "========= SIMULATION 1 COMPLETE! ============\n",
      "========= SIMULATION 2 COMPLETE! ============\n",
      "========= SIMULATION 3 COMPLETE! ============\n",
      "========= SIMULATION 4 COMPLETE! ============\n",
      "========= SIMULATION 5 COMPLETE! ============\n",
      "========= SIMULATION 6 COMPLETE! ============\n",
      "========= SIMULATION 7 COMPLETE! ============\n",
      "========= SIMULATION 8 COMPLETE! ============\n",
      "========= SIMULATION 9 COMPLETE! ============\n",
      "=============== Southeast U.S. SIMULATIONS COMPLETE ==============\n"
     ]
    }
   ],
   "source": [
    "shp = gpd.read_file('../Data/New EIWG LMEs/eiwg_boundaries_20230512_ZachS_ChangeLongto0_360.shp')\n",
    "lmes = list(shp['RegionName'])[:11]\n",
    "\n",
    "# Corresponding n_clusts values\n",
    "n_clusts = [2, 5, 3, 5, 2, 2, 3, 4, 2, 4, 5]\n",
    "\n",
    "lmes_n_clusts_dict = dict(zip(lmes, n_clusts))\n",
    "\n",
    "for lme, n_clust in lmes_n_clusts_dict.items():\n",
    "    spatial_xr, temporal_df, simulations_df = OSSE(lme, n_clust, n_sims = 10)\n",
    "    spatial_xr.to_netcdf(f'../Data/Fall 2023/{lme} Spatial Error.nc')\n",
    "    temporal_df.to_csv(f'../Data/Fall 2023/{lme} Temporal Error.csv')\n",
    "    simulations_df.to_csv(f'../Data/Fall 2023/{lme} Simulations Error.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xesmf_env]",
   "language": "python",
   "name": "conda-env-.conda-xesmf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
